# Personalised AI: A Model For A Proactive, Interview-Based Generation Architecture

By: Daniel Rosehill.

*Date: 28-Jan-25*

The purpose of this Github repository, like many that I create, is to gather together a few thoughts and sketches for an idea that I have been working on for a couple of months as context storage and assistants and agents have all quickly advanced in maturity.

These notes bring together a couple of system components that I have been working on previously in an attempt to map out how a unified system for achieving this objective would function. 

Large language models develop their capabilities and a working knowledge of the world through exposure to training data. The selection of this training data is hugely influential upon the functionality of the ultimate model created. Therefore, determinations are required in training data selection. 

Even domain specific training data, however, is not personalized. To state the obvious, nobody wants details like their bank balance to be in the public domain. However, we have seen that when even small amounts of personalized contextual data are exposed to large language models, the results in terms of more personalized and relevant inference can be dramatic. 

RAG has quickly emerged as the normative mechanism to make the injection of this contextual data work. Using embedding models, files are converted into numeric representations and stored in specialized databases optimized for access by models. 

In its most simple implementation, this can take the form of allowing the user to upload a single file into a vector database, which can then be provided to a model or an assistant. The user might upload their resume, which gets converted into chunks, and then that gets embedded into a vector store to which an agent providing personalized career advice is connected. 

At scale, this process can happen dynamically. Rather than requiring that users manually upload files, a data store that is being continuously populated, like an S3 bucket or a Google Drive, is connected to the vector database through a RAG pipeline. 

This process has created enormous excitement for the use cases of RAG in business workflows such as internal tool development. A support team can be provided with a model which has access to the company's JIRA or Confluence. In this manner the latest internal information is always available to the agent and in turn the users. 

Another implementation for context takes the form of using the user's ongoing conversation history with a model in order to distill contextual data from it. This is essentially a conversation store to memory unit pipeline. 

## Approaching contextual data generation deliberately 

A commonality between the RAG pipeline and the memory store approaches is that they take a passive approach to the creation and aggregation of context data. 

The context data that can ground and heighten LLM interface isn't created deliberately. Rather, it's extracted from existing knowledge and then converted into the requisite format for work with AI workloads. 

One deficiency of this approach is that while such systems can be highly effective, they are Long term gambits.Over time, a model can learn progressively more information about the user. This data footprint can be self correcting. But it requires a slow and patient approach that takes time before the utility of the contextual data may become apparent to end users. 

The system I've been working on implementing for contextual data creation takes an active approach to the initiative of building this data. The core of this idea is that rather than taking the view that we should attempt to graft our existing data stores onto AI tools, we should instead approach the process deliberately and actually invest time and effort in generating context data. 

The mechanism I've been exploring for doing this involves a composite of existing tools in a specific workflow as follows.

## 1: The "Interviewer"

The first component in this approach is an AI assistant whose task is to act as a inquisitive interviewer. Nothing particularly special is required to provision and deploy this assistant. It could be created on Open AI Assistants API or as a system prompt on top of any existing model. 

The ease with which AI assistants can be configured means that users don't need to be picky in how they create this configuration. A single interviewing bot could be created. Or an entire network of them could be created, each one charged with asking the user questions about a specific type of knowledge. 

The system prompts should configure the assistance to act as an inquisitive interviewer, asking the user questions. My thinking is that it makes sense to include in the system prompt details about why the Assistant is being asked to behave this way in order To give the interviewing assistant itself context about the project.

System prompt writing is a evolving art with no absolute right and wrongs. So this system prompt is offered in that vein as a very loose model:

*Your purpose is to act as a interviewer, asking the user questions. Your objective is to ask the user a wide ranging series of questions in order to gather significant amount of data about them and their life. Here are some contacts to clarify why you are being asked to do this. The user is proactively generating a bank of contextual data in order to ground inference from large language model assistants. To do this, the user needs a collection of contextual data about their life. So your purpose in asking the user questions is to assist with the generation of the files required for this process.*

*"At the beginning of your interaction with the user, ask whether the user would like you to ask questions about a specific field in order to focus the contacts that is generated on a particular domain. For example, the user might say today I'm working on developing contacts to improve some assistance related to my professional life. If that's the case, you might ask the user questions about his personal career objectives. Best jobs etc. If the user told you that they want to generate contextual data about their health, you might ask them to disclose their medication list and the medical history."*

Once you have clarified the scope of your questioning, you must begin by asking the user questions at random on this topic. Once you feel that you have gathered sufficient information to provide a contextual data file about a common topic within your own context window, you must present it to the user. 

If the context window is approaching, you must tell the user that you need to stop at this point in order to output the context data, and you can continue the conversation after you've done that. The "context window closing" for this purpose means that you judge that there is a risk that you will not be able to aggregate the gathered contextual information from the user within the space available in your output. 

The summary of the context data that you gather about the user's life should be written in the 3rd person and referred to the user as "the user." It should isolate the contextual data from the Broder corpus is of information that the user has provided. In doing so, you can discourage some pieces of information that are not relevant to creating context for grounding assistant performance. 

For example, you might capture this text from the user during the interview phase:

"I live in Jerusalem. Today I woke up with a small headache, but after drinking a few glasses of water I felt a lot better. Have a meeting tomorrow with my boss I work in sustainable finance."

From this information you might summarise:

"User lives in Jerusalem. User works in sustainable finance."

If the user states that you should take a more liberal approach to your definition of contextual data, then you should discard less information and include more details. 

An example using the first example of generated information from the user might be:

"User lives in Jerusalem. User occasionally suffers from headaches. User works in sustainable finance. "

You should output the contextual data snippets in the form of a continuous markdown block gathered within a code fence. 

## 2: The Vector Store Pipeline (Or Manual Approach)

The second part of this workflow involves either a more advanced agentic process or a more basic defined process. 

In the agentic process, the interviewing assistant would be configured with the ability to independently write data into the context data pipeline.

In the manual approach, the user would manually copy the contextual data snippet out of the chat with the interviewing user and manually upload that into their context data store. 

## 3: The Personal Agent

The rest of this approach is fairly straightforward. 

The context snippets that are gathered are aggregated into a single contextual data store. Technically, this might be a namespace within a vector database. 

This personal data store is then connected to an overarching personal assistant agent. 

This agent has a wide ranging configuration instructing them to provide general guidance to the user through the context of the personal data store. 

The more effort the user invests in conducting interviews with the first agent, and the more information is gathered into the personal context data store, the more accurate the output of the personal agent will be. Thus this mechanism and the ultimate user facing agent can improve over time. 

## 4: The Data Classification Agent

In the multi agent frameworks that are becoming very quickly a standard reality, we can think of ways in which this basic functionality can be extended further. 

We can think perhaps of the contextual data that comes into the initial vector database as a sort of slush pile of wide reaching information about the user. 

That slush pile might require careful segmentation in order to segregate between personally identifiable information and less private contextual data that could be exposed to more services. 

If such automatic segmentation were possible, then the contextual data store that the user takes ownership over could even be used as a sort of personal data footprint. That could be a replacement for manually providing small amounts of information to sign up forms, for example. 

## Data Federacy

I'm a long term advocate for personal data sovereignty and taking ownership over one's personal data. My view is that personal context data should properly remain the digital property of the user. 

Although the architecture envisioned might seem complicated, its intention is to decouple the user's personal contextual data from any one AI company, which might provide a front end to a tool and try to gather the contextual data through a pipeline that they manage. 

The problem with this approach is that the AI platform ultimately monopolizes the contextual data store. This approach to contextual data generation puts the control in the users hands. The user is responsible for proactively generating contextual data and can determine exactly how much of it they which to consolidate. 

The Assistant configuration above could be tweaked so that the user is able to refuse to answer a question. If the user refuses, the interviewing assistant just moves on to the next question and therefore that contextual data is never captured. 

## Potential Use-Cases

The proposed system for generating contextual data could be used to kick start a rag pipeline for both personal users as well as for enterprise users. 

Speech to Speech AI interfaces would make the process of conducting these interviews much more enjoyable for users.  Under this mechanism, a series of transcripts would be derived from audio based interviews and these would be fed into the vector database. The user could conduct a one hour interview while jogging or going for a brisk walk, and even find the process of providing details about their life to the interviewing assistant oddly enjoyable! Tools like Vapi would be ideal for this purpose and An automation pipeline could be configured whereby transcripts are automatically fed into the ingress pipeline for the vector database.

In the business use case, this same methodology could be used in order to create a focused initial contextual data store. A sales team might have an internal AI tool at their disposal with a RAG pipeline feeding into it. But if they huddled around a speakerphone and provided a focus session on their targets for the quarter, this might yield a much more focused and robust pool of contextual data that could provide the initial population to a model. 

There is no reason to think that all three of these systems could not coexist in a happy sort of symbiosis. That is to say, the data sources feeding into the context or could come from multiple directions all at the same time. And as vector databases move towards read write architectures, One context door could even correct contacts provided by another or update it. 

The chat history, the deliberately created context data and the information from internal tools could all be combined into one overarching context repository, which could in turn be connected to LLMs and other AI tools.

## Author

Daniel Rosehill  
(public at danielrosehill dot com)

## Licensing

This repository is licensed under CC-BY-4.0 (Attribution 4.0 International) 
[License](https://creativecommons.org/licenses/by/4.0/)

### Summary of the License
The Creative Commons Attribution 4.0 International (CC BY 4.0) license allows others to:
- **Share**: Copy and redistribute the material in any medium or format.
- **Adapt**: Remix, transform, and build upon the material for any purpose, even commercially.

The licensor cannot revoke these freedoms as long as you follow the license terms.

#### License Terms
- **Attribution**: You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.
- **No additional restrictions**: You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.

For the full legal code, please visit the [Creative Commons website](https://creativecommons.org/licenses/by/4.0/legalcode).